<!-- ai-security.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>AI Security — ObfusLabs</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    :root{
      --bg:#0a0a0a;        /* black */
      --fg:#f0f0f0;        /* white */
      --muted:#bfbfbf;
      --muted2:#9a9a9a;
      --accent:#FF2B63;    /* ObfusLabs red */
      --neon:#00FF00;      /* very occasional neon */
      --line:rgba(255,255,255,0.03);
    }
    /* Base */
    html,body{background:var(--bg); color:var(--fg); font-family:'Courier New', Courier, monospace;}
    body{padding:3rem; line-height:1.6; max-width:980px; margin:0 auto;}
    a{color:#fff; text-decoration:underline; text-decoration-color:var(--accent);}
    a:hover{color:var(--accent);}
    /* Logo */
    .logo{
      font-size:2.2rem; letter-spacing:0.6rem; display:flex;
      margin-bottom:2.5rem; /* ensure image never collides */
      user-select:none;
    }
    .char{display:inline-block; transition:color .3s;}
    .char.red{color:var(--accent);}
    /* Header + meta */
    header{margin-bottom:1rem;}
    .meta{color:var(--muted2); font-size:.95rem; margin:.2rem 0 1rem;}
    /* Post container */
    .post{
      background:rgba(255,255,255,0.02);
      border:1px solid var(--line);
      padding:1.5rem;
    }
    /* Hero image: smaller, contained, responsive, no overlap */
    .hero-img{
      width:100%;
      height:220px;                       /* compact banner */
      display:flex; align-items:center; justify-content:center;
      border:1px dashed var(--line);
      background:linear-gradient(90deg, rgba(255,255,255,0.02), rgba(255,255,255,0.01));
      margin:1rem 0 1.5rem 0;
      overflow:hidden; padding:0;
    }
    .hero-img img{
      max-width:100%; max-height:100%;
      object-fit:contain; display:block;
    }
    @media (max-width:520px){ .hero-img{height:200px;} }
    @media (min-width:1024px){ .hero-img{height:260px;} }

    /* Layout grid */
    .grid{display:grid; grid-template-columns:1fr; gap:1rem;}
    @media (min-width:820px){ .grid{grid-template-columns:1.2fr .8fr;} }

    .small{font-size:.9rem; color:var(--muted);}
    .note{color:var(--muted); font-size:.95rem; margin-top:1rem;}
    .list-tight{margin:.5rem 0 .5rem 1.1rem;}
    .callout{
      background:rgba(255,255,255,0.03);
      border:1px dashed rgba(255,255,255,0.08);
      padding:.9rem; margin:1rem 0; color:#e6e6e6;
    }
    .repo{display:inline-block; margin-top:.4rem;}
    .back{margin-top:1rem; display:inline-block;}

    /* Tiny neon accent—very subtle */
    .repo:hover{ text-shadow:0 0 6px rgba(0,255,0,0.25); }
  </style>
</head>
<body>
  <div class="logo" aria-hidden="true">
    <span class="char">O</span>
    <span class="char red">B</span>
    <span class="char">F</span>
    <span class="char" id="glitch-letter">Ʞ</span>
    <span class="char">S</span>
    <span class="char">L</span>
    <span class="char">Δ</span>
    <span class="char red">B</span>
    <span class="char">S</span>
  </div>

  <header>
    <h1>AI Security</h1>
    <div class="meta">CS50AI completion • adversarial ML, model misuse, and autonomy risk through a red-team lens</div>
  </header>

  <article class="post">
    <div class="meta"><strong>Date:</strong> Sep 15, 2025 <span class="small">• Foundations finished; security experiments ongoing</span></div>

    <div class="hero-img" id="image-placeholder">
      <!-- Swap filename to your final asset (e.g., ai-locks.png or ai-pic.png) -->
      <img src="ai-locks.png" alt="Neural network diagram with secured paths (locks)"/>
    </div>

    <section class="content grid">
      <div>
        <h2>Summary</h2>
        <p class="note">
          We completed <em>CS50’s Introduction to Artificial Intelligence with Python</em> and are applying that foundation to practical AI security:
          prompt injection & jailbreaks, data poisoning, adversarial examples, and safe deployment patterns. Our stance is simple:
          treat models like production software with an attack surface — then try to break them.
        </p>

        <h2>Immediate surface (now → 2–5 years)</h2>
        <ul class="list-tight small">
          <li><strong>Prompt injection & jailbreaks:</strong> untrusted content steering model behavior; indirect prompt attacks via tools/RAG.</li>
          <li><strong>Data leakage via embeddings & fine-tuning:</strong> sensitive info exfiltrated from vector stores or tuned models.</li>
          <li><strong>Data poisoning & model supply chain:</strong> tampered training sets, malicious weights, dependency risks.</li>
          <li><strong>Adversarial examples:</strong> tiny perturbations that flip labels; physical attacks (stickers/patches) against vision models.</li>
          <li><strong>Operational controls:</strong> auth to model endpoints, rate-limits, logging/review, sandboxed tool use, kill-switches.</li>
        </ul>

        <div class="callout">
          <strong>What we test:</strong> can untrusted inputs hijack the model or tools? can we exfiltrate secrets from embeddings? can small perturbations flip a decision?
        </div>

        <h2>Near-term autonomy risk (5–15 years)</h2>
        <p class="small">
          The “killer robot” concern isn’t sci-fi — the software logic is trivial; hardware cost is the bottleneck.
          As autonomous drones/UGVs become cheaper, the insider-threat/misuse problem turns into a policy and security emergency.
          Our focus: <em>control</em> — authorization, geofencing, remote shutdown, and preventing model-driven escalation.
        </p>

        <h2>Longer-term (and why we still care)</h2>
        <p class="small">
          General intelligence and recursive self-improvement are hard to scope operationally today, but our day-job defenses
          (verification, monitoring, containment, least-privilege, red-teaming) are the same muscles we’ll need if capabilities bend faster.
        </p>

        <h2>What we finished</h2>
        <ul class="list-tight small">
          <li>CS50AI core topics: search, logic, probability, optimization, neural networks, reinforcement learning.</li>
          <li>All programming assignments and projects are public.</li>
        </ul>
        <p class="small">
          Repo: <a class="repo" href="https://github.com/exitvillain/harvard-artificial-intelligence" target="_blank" rel="noopener noreferrer">
          github.com/exitvillain/harvard-artificial-intelligence</a>
        </p>

        <h2>What we’re building next</h2>
        <ul class="list-tight small">
          <li>Minimal prompt-injection test harness for RAG/tool-using agents (attack strings + expected defenses).</li>
          <li>Tiny adversarial-example demo (image classifier flip; physical printable patch optional).</li>
          <li>Embedding-leak lab: measure semantic drift and secret retrieval risks from vector stores.</li>
          <li>Ops hardening checklist for ML endpoints (authN/Z, quotas, content filters, review gates, kill-switches).</li>
        </ul>

        <h2>A tiny promise</h2>
        <p class="note">
          We’ll work to harden deployed models — and if robots start acting less friendly than they should, we plan to know which switch to try first.
        </p>

        <p class="back"><a href="current-research.html">← Back to Current Research</a></p>
      </div>

      <aside>
        <h3>Foundations (short note)</h3>
        <p class="small">
          Embeddings (e.g., word2vec) showed how meaning can live in geometry — similar words cluster in vector space.
          Modern transformers scale this idea massively. We keep this here as the conceptual bridge to why adversarial
          perturbations and poisoning work at all.
        </p>

        <h3>Show, don’t tell</h3>
        <ul class="list-tight small">
          <li>Prefer runnable artifacts to certificate photos.</li>
          <li>Short writeups, clear PoCs, tight scope.</li>
        </ul>

        <h3>Image tip</h3>
        <p class="small">Use your red/white/black “locked paths” art for this page. Keep neon to a minimum for consistency.</p>
      </aside>
    </section>
  </article>

  <footer style="margin-top:2rem; color:#7a7a7a;">
    <p>Questions or collabs: <a href="mailto:daniel.gray@obfuslabs.com">daniel.gray@obfuslabs.com</a></p>
  </footer>

  <script>
    const glitch = document.getElementById('glitch-letter');
    const states = ['█','ʞ','U'];
    let i=0;
    setInterval(()=>{glitch.textContent=states[i%states.length]; i++;},700);
  </script>
</body>
</html>

